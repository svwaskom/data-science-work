---
title: "Deriving Data"
author: Zachary del Rosario
date: 2020-05-07
output: github_document
time: 15
reading: 60
---

*Purpose*: Often our data will not tell us *directly* what we want to know; in
these cases we need to *derive* new quantities from our data. In this exercise,
we'll work with `mutate()` to create new columns by operating on existing
variables, and use `group_by()` with `summarize()` to compute aggregate
statistics (summaries!) of our data.

*Reading*: [Derive Information with dplyr](https://rstudio.cloud/learn/primers/2.3)
*Topics*: (All topics, except *Challenges*)
*Reading Time*: ~60 minutes

*Note*: I'm considering splitting this exercise into two parts; I welcome
feedback on this idea.

```{r setup, include=FALSE}
# knitr options
knitr::opts_chunk$set(echo = TRUE)
```

```{r library}
library(tidyverse)

```

__q1__ What is the difference between these two versions? How are they the same?
How are they different?

```{r q1-task}
## Version 1
filter(diamonds, cut == "Ideal")
## Version 2
diamonds %>% filter(cut == "Ideal")
```
**Answer**:
- They produce exactly the same results.  Version 2 just uses piping to pass in the `diamonds` dataframe into the `filter` function.

The reading mentioned various kinds of *summary functions*, which are summarized
in the table below:

### Summary Functions

| Type | Functions |
| ---- | --------- |
| Location | `mean(x), median(x), quantile(x, p), min(x), max(x)` |
| Spread | `sd(x), var(x), IQR(x), mad(x)` |
| Position | `first(x), nth(x, n), last(x)` |
| Counts | `n_distinct(x), n()` |
| Logical | `sum(!is.na(x)), mean(y == 0)` |

__q2__ Using `summarize()` and a logical summary function, determine the number
of rows with `Ideal` `cut`. Save this value to a column called `n_ideal`.

```{r q2-task}
df_q2 <- diamonds %>% 
  summarise(n_ideal = sum(cut == "Ideal"))
df_q2
```

The following test will verify that your `df_q2` is correct:

```{r q2-tests}
## NOTE: No need to change this!
assertthat::assert_that(
  assertthat::are_equal(
    df_q2 %>% pull(n_ideal),
    21551
  )
)
print("Great job!")
```

__q3__ The function `group_by()` modifies how other dplyr verbs function.
Uncomment the `group_by()` below, and describe how the result changes.

```{r q3-task}
diamonds %>%
  ## group_by(color, clarity) %>%
  summarize(price = mean(price))

diamonds %>%
  group_by(color, clarity) %>%
  summarize(price = mean(price))
```
**Answer**:
- Prior to the `group_by` call, it returned the mean price for the entire dataset.
- After adding `group_by(color, clarity)`, it now returns the mean price for each combination of `color` and `clarity`.

### Vectorized Functions

| Type | Functions |
| ---- | --------- |
| Arithmetic ops. | `+, -, *, /, ^` |
| Modular arith. | `%/%, %%` |
| Logical comp. | `<, <=, >, >=, !=, ==` |
| Logarithms | `log(x), log2(x), log10(x)` |
| Offsets | `lead(x), lag(x)` |
| Cumulants | `cumsum(x), cumprod(x), cummin(x), cummax(x), cummean(x)` |
| Ranking | `min_rank(x), row_number(x), dense_rank(x), percent_rank(x), cume_dist(x), ntile(x)` |

__q4__ The `depth` variable is supposedly computed via `depth_computed = 2 * z /
(x + y)`. Compute `diff = depth - depth_computed`, and compute the summary
*coefficient of variation* `cov = sd(x) / mean(x)`. Assign the resulting tibble
to `df_q4`.

```{r q4-task}
## TODO: Assign result to df_q4
# SW: dude.  this went way deep way fast.
# lso, the solution uses na.rm = TRUE which...like, what?  and we haven't talked about coefficient of variation yet, I don't think
df_q4 <- diamonds %>% 
  mutate(
    depth_computed = 2 * z / (x + y), 
    diff = depth - depth_computed
    )  %>%
  summarise(
    diff_mean = mean(diff, na.rm = TRUE), #note that i do not understand na.rm
    diff_sd = sd(diff, na.rm = TRUE),
    cov = diff_sd / diff_mean
    )
df_q4
# S
```

The following test will verify that your `df_q4` is correct:

```{r q4-tests}
## NOTE: No need to change this!
assertthat::assert_that(
  assertthat::are_equal(
    df_q4 %>%
      select(cov) %>%
      mutate_all(~round(., digits = 3)),
    tibble(
      cov = 0.023
    )
  )
)
print("Nice!")
```

The coefficient of variation here is quite small, about 2 percent. This is not a
huge level of variation, but it does raise questions about why the values don't
agree!

__q5__ Compute the `price_mean = mean(price)`, `price_sd = sd(price)`, and
`price_cov = price_mean / price_sd` for each `cut` of diamond. What observations
can you make about the various cuts? Do those observations match your expectations?

```{r q5-task}
## TODO: Assign result to df_q5
# SW: note that your instructions say `price_cov = price_mean / price_sd`, but that's backwards
df_q5 <- diamonds %>% 
  group_by(cut) %>% 
  summarise(
    price_mean = mean(price),
    price_sd = sd(price),
    price_cov = price_sd / price_mean
  )
df_q5
```

The following test will verify that your `df_q5` is correct:

```{r q5-tests}
## NOTE: No need to change this!
# SW: this is broken, even in the master file
assertthat::assert_that(
  assertthat::are_equal(
    df_q5 %>%
      select(cut, price_cov) %>%
      mutate(price_cov = round(price_cov, digits = 3)),
    tibble(
      cut = c("Fair", "Good", "Very Good", "Premium", "Ideal"),
      price_cov = c(0.817, 0.937, 0.988, 0.949, 1.101)
    ) %>%
    mutate(cut = fct_inorder(cut, ordered = TRUE))
  )
)
print("Excellent!")
```

**Observations**:

- The covariants are very high, which means that the price varies a lot for diamonds of the same `cut`.  
- From that, I infer that other variables are also used to determine price.

<!-- include-exit-ticket -->
# Exit Ticket
<!-- -------------------------------------------------- -->

Once you have completed this exercise, make sure to fill out the **exit ticket survey**, [linked here](https://docs.google.com/forms/d/e/1FAIpQLSeuq2LFIwWcm05e8-JU84A3irdEL7JkXhMq5Xtoalib36LFHw/viewform?usp=pp_url&entry.693978880=e-data02-derive-assignment.Rmd).
